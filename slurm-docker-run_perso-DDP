#!/bin/bash
# https://github.com/NVIDIA/nvidia-docker/issues/1026
# this is working: docker run --network=host --cap-add=IPC_LOCK --device=/dev/infiniband --gpus '"device=0,1"' horovod/horovod:0.18.1-tf1.14.0-torch1.2.0-mxnet1.5.0-py3.6 nvidia-smi

# $1 = primary|secondary
# $2 = Horovod Container Name
# $3 = user ID
# $4 = group ID
# $5 = working directory about scripts (under /home/group/user/working_directory) 
# $6 = working directory about data (under /scratch/group/user/working_directory)
# $7 = path to the python script
# $8 = arguments of the python script (optional) 

CONTAINER_NAME=$2
UID=$3
GID=$4
HOME_DIR=$5
OUTPUT_DIR=$6
DATA_DIR=$7
PYTHON_SCRIPT=$8
ARGS=$9
CONFIG_FILE=${10}

echo "docker_run_perso-DDP :CONFIG_FILE=${CONFIG_FILE}"

ARGS2="${ARGS//|/ }"

# Define Docker options
DOCKER_OPTS="--ipc=host --ulimit nofile=1048576:1048576 --name=slurm-$SLURM_JOB_ID -e CONFIG_FILE=$CONFIG_FILE"   #assign a name to the container -> used to give a name to the output slurm job
#DOCKER_MOUNTS_OPTS=" -v $(echo ~/.ssh):/tmp/.ssh:ro -v /scratch:/scratch -v /home:/home"  #mount the different directories 
DOCKER_MOUNTS_OPTS=" -v $(echo ~/.ssh):/tmp/.ssh:ro -v ${HOME_DIR}:${HOME_DIR} -v ${DATA_DIR}:${DATA_DIR} -v ${OUTPUT_DIR}:${OUTPUT_DIR}"   #mount the different directories
MLX_OPTS="--network=host --cap-add=IPC_LOCK --device=/dev/infiniband"    #options about the infiniband network 

# Define ssh command
SSHD_COMMAND="cp -R /tmp/.ssh /root/.ssh; chown root:root /root/.ssh; chmod 600 /root/.ssh; /usr/sbin/sshd -p ${UID}"

#Parameters for Horovod to perform multi-GPUs computing
HOROVOD_NB_GPUS=$(echo "${SLURM_STEP_GPUS}" | awk -F"," '{print NF}')
HOROVOD_NB_TASKS=$((SLURM_JOB_NUM_NODES*HOROVOD_NB_GPUS))
HOROVOD_HOSTLIST=$(scontrol show hostnames|sed "s/$/:${HOROVOD_NB_GPUS}/"|paste -d, -s)

#Shell script which is executed inside each container. It is temporary; it is generated for each slurm job  
RUNME_SCRIPT=/tmp/slurm-docker-run.$$.sh

echo "#!/bin/bash" > $RUNME_SCRIPT
#env | sed "s/^/`hostname`:/"
echo GPUs: "${SLURM_STEP_GPUS}"

if [ "$1" == "secondary" ] ; then
    echo docker run --rm --gpus \'\"device=$SLURM_STEP_GPUS\"\' ${MLX_OPTS} ${DOCKER_OPTS} ${DOCKER_MOUNTS_OPTS} ${CONTAINER_NAME} bash -c \"eval ${SSHD_COMMAND}\; sleep infinity\"

elif [ "$1" == "primary" ]; then
    echo docker run --rm --gpus \'\"device=$SLURM_STEP_GPUS\"\' ${MLX_OPTS} ${DOCKER_OPTS} ${DOCKER_MOUNTS_OPTS} ${CONTAINER_NAME} bash -c \" torchrun --nproc_per_node=$HOROVOD_NB_GPUS ${PYTHON_SCRIPT} ${ARGS2} \|\& grep -Fv -e \'Read -1\' -e \'NCCL INFO\'\; chown -R ${UID}:${GID} ${HOME_DIR} ${OUTPUT_DIR}\; chown -R 24985:2920 ${DATA_DIR} \"

# chown gives back property to user / group for home dir and output dir, and data_dir property to data "owner" brochetc mrmn
   
else
    echo echo ERROR
fi >> $RUNME_SCRIPT

cat $RUNME_SCRIPT
bash $RUNME_SCRIPT


docker ps

rm $RUNME_SCRIPT
